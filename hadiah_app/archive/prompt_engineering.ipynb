{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bcc493-150f-4a75-ba94-f05446e70bdb",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fc472-6c00-4613-9c9d-6b0d590d0653",
   "metadata": {},
   "source": [
    "### Simple code to impliment togather API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00acf89-08aa-4a15-a75d-a90570389a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city that never sleeps! New York has endless options for entertainment, culture, and adventure. Here are some fun things to do in New York:\n",
      "\n",
      "**Iconic Landmarks:**\n",
      "\n",
      "1. Statue of Liberty and Ellis Island: Take a ferry to Liberty Island to see the iconic statue up close and visit the Ellis Island Immigration Museum.\n",
      "2. Central Park: Explore the 843-acre park, which offers walking paths, lakes, restaurants, and plenty of people-watching opportunities.\n",
      "3. Times Square: Experience the bright lights, giant billboards, and lively atmosphere of the \"Crossroads of the World.\"\n",
      "4. Brooklyn Bridge: Walk or bike across the iconic bridge for spectacular city views.\n",
      "5. Empire State Building: Enjoy panoramic views of the city from the observation deck on the 86th floor.\n",
      "\n",
      "**Museums and Galleries:**\n",
      "\n",
      "1. The Metropolitan Museum of Art: One of the world's largest and most renowned museums, with a collection that spans over 5,000 years of human history.\n",
      "2. American Museum of Natural History: Explore exhibits on dinosaurs, space, and the natural world.\n",
      "3. Museum of Modern Art (MoMA): Discover an extensive collection of modern and contemporary art.\n",
      "4. Guggenheim Museum: Admire the unique architecture and innovative exhibitions.\n",
      "5. 9/11 Memorial & Museum: A poignant tribute to the victims of the 9/11 attacks.\n",
      "\n",
      "**Food and Drink:**\n",
      "\n",
      "1. Try a classic New York-style pizza slice at Lombardi's, Joe's Pizza, or Patsy's Pizzeria.\n",
      "2. Visit a food market like Smorgasburg or Chelsea Market for a taste of the city's diverse culinary scene.\n",
      "3. Explore the vibrant neighborhoods of Chinatown, Little Italy, and Koreatown for authentic international cuisine.\n",
      "4. Take a food tour of the city to sample the best eats and drinks.\n",
      "5. Visit a rooftop bar like 230 Fifth or The Top of the Strand for stunning city views and craft cocktails.\n",
      "\n",
      "**Performing Arts:**\n",
      "\n",
      "1. Broadway Shows: Catch a performance of a hit musical or play on the Great White Way.\n",
      "2. Lincoln Center: Attend a concert, ballet, or opera performance at this world-renowned cultural complex.\n",
      "3. Carnegie Hall: Experience the iconic concert venue, which hosts a wide range of musical performances.\n",
      "4. Jazz Clubs: Visit legendary clubs like Blue Note, Village Vanguard, or Birdland for live jazz music.\n",
      "5. Comedy Clubs: Laugh out loud at comedy clubs like Carolines on Broadway or the Comedy Cellar.\n",
      "\n",
      "**Outdoor Activities:**\n",
      "\n",
      "1. Walk or bike along the Hudson River Greenway: Enjoy the scenic views of the river and the city.\n",
      "2. Visit the High Line: An elevated park built on an old rail line, offering stunning views of the city.\n",
      "3. Explore the Bronx's Van Cortlandt Park: A large park with hiking trails, lakes, and plenty of green space.\n",
      "4. Take a stroll through Greenwich Village: Admire the charming streets, historic brownstones, and lively atmosphere.\n",
      "5. Visit Coney Island: Enjoy the beach, amusement park, and classic boardwalk eats like hot dogs and funnel cakes.\n",
      "\n",
      "**Sports:**\n",
      "\n",
      "1. Catch a Yankees or Mets game at Yankee Stadium or Citi Field.\n",
      "2. Visit Madison Square Garden: Home of the New York Knicks (basketball) and New York Rangers (hockey).\n",
      "3. Take a tour of the US Open tennis tournament at Flushing Meadows Corona Park.\n",
      "4. Attend a Brooklyn Nets game at the Barclays Center.\n",
      "5. Watch a New York Giants or New York Jets game at MetLife Stadium (located in New Jersey, just outside the city).\n",
      "\n",
      "These are just a few of the many fun things to do in New York. With its endless energy, diverse neighborhoods, and world-class attractions, the city has something for everyone!"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together(api_key=\"\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"}],\n",
    "    max_tokens=None,\n",
    "    temperature=0.7,\n",
    "    top_p=0.7,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1,\n",
    "    stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for token in response:\n",
    "    if hasattr(token, 'choices'):\n",
    "        print(token.choices[0].delta.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851aa9cc-b9ff-49c2-8a3d-c0e6741ce638",
   "metadata": {},
   "source": [
    "## Implimentation of Togather API with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d16be0a-19b2-4595-9d34-d93e94ba171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from together import Together\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize the Together client\n",
    "# You should use environment variables for API keys in production\n",
    "api_key = \"\"  # In production, use os.environ.get(\"TOGETHER_API_KEY\")\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "def generate_response(role, prompt, temperature=0.7, top_p=0.7, top_k=50, max_tokens=1024, model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"):\n",
    "    \"\"\"Generate a response from the Together API\"\"\"\n",
    "    try:\n",
    "        # Create a completion using the Together API\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": role, \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=1,\n",
    "            stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "            stream=False  # We'll set this to False for the Gradio interface\n",
    "        )\n",
    "        \n",
    "        # Extract and return the response content\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def stream_response(role, prompt, temperature=0.7, top_p=0.7, top_k=50, max_tokens=1024, model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\"):\n",
    "    \"\"\"Stream a response from the Together API\"\"\"\n",
    "    try:\n",
    "        # Create a streaming completion\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": role, \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            top_k=top_k,\n",
    "            repetition_penalty=1,\n",
    "            stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Stream the response token by token\n",
    "        full_response = \"\"\n",
    "        for token in response:\n",
    "            if hasattr(token, 'choices') and token.choices[0].delta.content is not None:\n",
    "                chunk = token.choices[0].delta.content\n",
    "                full_response += chunk\n",
    "                # Yield the updated response\n",
    "                yield full_response\n",
    "                time.sleep(0.01)  # Small delay for readability\n",
    "        \n",
    "        return full_response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Function to handle flagging\n",
    "def flag_interaction(role, prompt, response, model, temperature, top_p, top_k, max_tokens):\n",
    "    \"\"\"Save flagged interaction to CSV file\"\"\"\n",
    "    import csv\n",
    "    import datetime\n",
    "    \n",
    "    # Create a timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Prepare the data\n",
    "    data = [timestamp, role, prompt, response, model, temperature, top_p, top_k, max_tokens]\n",
    "    \n",
    "    # Write to CSV file\n",
    "    try:\n",
    "        file_exists = os.path.isfile('flagged_interactions.csv')\n",
    "        with open('flagged_interactions.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if not file_exists:\n",
    "                writer.writerow(['Timestamp', 'User Role', 'Prompt', 'Response', 'Model', 'Temperature', 'Top P', 'Top K', 'Max Tokens'])\n",
    "            writer.writerow(data)\n",
    "        return \"Interaction flagged successfully!\"\n",
    "    except Exception as e:\n",
    "        return f\"Error flagging interaction: {str(e)}\"\n",
    "\n",
    "# Define available models\n",
    "models = [\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
    "    \"meta-llama/Llama-Vision-Free\",\n",
    "]\n",
    "\n",
    "# Define available roles\n",
    "roles = [\"user\", \"system\", \"assistant\"]\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks(title=\"Together AI Chat Interface\") as demo:\n",
    "    gr.Markdown(\"# Together AI Chat Interface\")\n",
    "    gr.Markdown(\"Interact with language models through the Together AI API\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            role_dropdown = gr.Dropdown(\n",
    "                label=\"User Role\",\n",
    "                choices=roles,\n",
    "                value=\"user\"\n",
    "            )\n",
    "            prompt_input = gr.Textbox(\n",
    "                label=\"Your Prompt\",\n",
    "                placeholder=\"Enter your prompt here...\",\n",
    "                lines=4\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            with gr.Accordion(\"Model Parameters\", open=False):\n",
    "                model_dropdown = gr.Dropdown(\n",
    "                    label=\"Model\",\n",
    "                    choices=models,\n",
    "                    value=models[0]\n",
    "                )\n",
    "                temperature_slider = gr.Slider(\n",
    "                    label=\"Temperature\",\n",
    "                    minimum=0.1,\n",
    "                    maximum=1.0,\n",
    "                    value=0.7,\n",
    "                    step=0.1\n",
    "                )\n",
    "                top_p_slider = gr.Slider(\n",
    "                    label=\"Top P\",\n",
    "                    minimum=0.1,\n",
    "                    maximum=1.0,\n",
    "                    value=0.7,\n",
    "                    step=0.1\n",
    "                )\n",
    "                top_k_slider = gr.Slider(\n",
    "                    label=\"Top K\",\n",
    "                    minimum=1,\n",
    "                    maximum=100,\n",
    "                    value=50,\n",
    "                    step=1\n",
    "                )\n",
    "                max_tokens_slider = gr.Slider(\n",
    "                    label=\"Max Tokens\",\n",
    "                    minimum=64,\n",
    "                    maximum=4096,\n",
    "                    value=1024,\n",
    "                    step=64\n",
    "                )\n",
    "                \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Generate Response\")\n",
    "        stream_btn = gr.Button(\"Stream Response\")\n",
    "        clear_btn = gr.Button(\"Clear\")\n",
    "    \n",
    "    output_area = gr.Textbox(\n",
    "        label=\"Response\",\n",
    "        lines=10,\n",
    "        show_copy_button=True\n",
    "    )\n",
    "    \n",
    "    # Add a flag button\n",
    "    flag_btn = gr.Button(\"Flag this interaction\")\n",
    "    flag_status = gr.Textbox(label=\"Flag Status\", visible=True)\n",
    "    \n",
    "    # Set up event handlers\n",
    "    submit_btn.click(\n",
    "        fn=generate_response,\n",
    "        inputs=[role_dropdown, prompt_input, temperature_slider, top_p_slider, top_k_slider, max_tokens_slider, model_dropdown],\n",
    "        outputs=output_area\n",
    "    )\n",
    "    \n",
    "    stream_btn.click(\n",
    "        fn=stream_response,\n",
    "        inputs=[role_dropdown, prompt_input, temperature_slider, top_p_slider, top_k_slider, max_tokens_slider, model_dropdown],\n",
    "        outputs=output_area\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(\n",
    "        fn=lambda: (\"user\", \"\", \"\"),\n",
    "        inputs=None,\n",
    "        outputs=[role_dropdown, prompt_input, output_area]\n",
    "    )\n",
    "    \n",
    "    # Set up flag button handler\n",
    "    flag_btn.click(\n",
    "        fn=flag_interaction,\n",
    "        inputs=[\n",
    "            role_dropdown,\n",
    "            prompt_input,\n",
    "            output_area,\n",
    "            model_dropdown,\n",
    "            temperature_slider,\n",
    "            top_p_slider,\n",
    "            top_k_slider,\n",
    "            max_tokens_slider\n",
    "        ],\n",
    "        outputs=flag_status\n",
    "    )\n",
    "    \n",
    "    # Some example prompts\n",
    "    example_prompts = [\n",
    "        [\"user\", \"What are some fun things to do in New York?\"],\n",
    "        [\"user\", \"Explain quantum computing to a 10-year-old.\"],\n",
    "        [\"system\", \"You are a helpful AI assistant who speaks like a pirate.\"],\n",
    "        [\"user\", \"What are the main differences between Python and JavaScript?\"]\n",
    "    ]\n",
    "    \n",
    "    gr.Examples(\n",
    "        examples=example_prompts,\n",
    "        inputs=[role_dropdown, prompt_input]\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True, server_name=\"0.0.0.0\")  # share=True creates a public link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af6267-47e6-4902-884c-7cf1a1b27c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-work1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
